---
title: "The Effects of Consultant Use on Environmental Justice Planning"
author: "Aaron Guerra"
format: pdf
fontsize: 12pt
linestretch: 1.2
classoption: oneside
geometry: margin=1in
mainfont: Times New Roman
sansfont: Times New Roman
number-sections: false
pagestyle: plain
bibliography: references.bib
suppress-bibliography: false
---

```{r}
#| echo: false
#| output: false
library(tidyverse)
library(quanteda)
library(quanteda.textstats)
library(topicmodels)
library(tidytext)
library(tidycensus)
library(stargazer)

plans_corpus_doc <- readRDS("plans_corpus_doc.rds")
plan_corpus_by_page <- readRDS("plans_corpus_by_page.rds")

ej_corpus <- corpus_subset(plans_corpus_doc, 
                           plan_type == "EJE")

ca_data <- get_acs(geography='place',
                       state='California',
                       variables = c('B01003_001', #population
                                     'B19013_001' # mhi
                                     ))
census_data <- ca_data %>% 
  mutate(city_name = str_remove(NAME, " city, California")) %>%
  select(-c(NAME, moe, GEOID)) %>%
  pivot_wider(names_from = variable,
              values_from = estimate) %>% 
  rename(population = B01003_001,
         mhi = B19013_001) 

docvar_df <- docvars(ej_corpus) %>% 
  tibble() %>% 
  cbind(docnames(ej_corpus)) %>% 
  select(`docnames(ej_corpus)`, city_name, plan_year, plan_length) %>% 
  rename(doc_id = `docnames(ej_corpus)`) %>% 
  left_join(census_data, 
            by = "city_name")  %>% 
  mutate(pop_bin = ifelse(population > median(population), 1, 0),
         mhi_bin = ifelse(mhi > median(mhi), 1, 0),
         county = c('Contra Costa', #antioch
                    'Kern', #arvin
                    'Los Angeles', #gardena
                    'Los Angeles', #inglewood
                    'Los Angeles', #lynwood
                    'Los Angeles', #maywood
                    'San Mateo', #menlo park
                    'Los Angeles', #monrovia
                    'Alameda', #oakland
                    'Riverside', #perris
                    'San Bernardino', #rialto
                    'Riverside', #riverside
                    'Orange' #san juan capistrano
                    ), 
         consultant  = c('Urban Planning Partners Inc.', #antioch
                    'City of Arvin', #arvin
                    'City of Gardena', #gardena
                    'Civic Solutions', #inglewood
                    'Infrastructure Engineers', #lynwood
                    'City of Maywood', #maywood
                    'M-Group', #menlo park
                    'City of Monrovia', #monrovia
                    'Dyetta & Bhatia', #oakland
                    'National Community Renaissance of California', #perris
                    'Dudek', #rialto
                    'City of Riverside', #riverside
                    'City of San Juan Capistrano' #san juan capistrano
                    ), 
         used_consultant = c(1,
                             0,
                             0,
                             1,
                             1,
                             0,
                             1,
                             0,
                             1,
                             1,
                             1,
                             0,
                             0)
         ) %>% 
  select(-c(population, mhi))

docvars(ej_corpus) <- docvar_df

cities <- tolower(unlist(str_split(as.character(docvars(ej_corpus)$city_name), ' ')))
counties <- tolower(unlist(str_split(unique(as.character(docvar_df$county)), ' ')))
place_names_remove <- c(cities, 
                        str_c(cities, "â€™s"), 
                        counties)

two_letters <- c()
for (letter in letters) {
  two_letters <- c(two_letters, str_c(letters, letter))
  }

ej_tokens <- tokens(ej_corpus) %>% 
  tokens_tolower() %>% 
  tokens_remove(place_names_remove) %>%
  tokens_remove(stopwords("en")) %>%
  tokens_remove(c('st', 'ave', 'rd', 'blvd'))%>% 
  tokens(split_hyphens = TRUE,
         remove_punct = TRUE,
         remove_symbols = TRUE,
         remove_numbers = TRUE) %>%
  tokens_remove(letters) %>% 
  tokens_remove(two_letters) 

ej_dfm <- ej_tokens %>% 
  dfm() %>% 
  dfm_tfidf() %>% 
  dfm_trim(min_docfreq = 2,
           docfreq_type = "count")

ej_dfm <- ej_dfm[rowSums(ej_dfm) > 0, ] 

freq <- textstat_frequency(ej_dfm, force=TRUE); freq

# ej_dfm %>%
#   textstat_frequency(groups=county, force=TRUE) %>%
#   group_by(group) %>%
#   slice_max(order_by = frequency, n = 5) %>%
  # arrange(group, desc(frequency))
# 
# ej_dfm %>% 
#   textstat_frequency(groups=used_consultant, force=TRUE) %>% 
#   group_by(group) %>% 
#   slice_max(order_by = frequency, n = 20) %>% 
#   arrange(group, desc(frequency))

eje_sim_df <- tibble(as.data.frame(textstat_simil(ej_dfm,  method='cosine'))) %>% 
  left_join(docvar_df, 
            by = c("document1" = "doc_id")) %>% 
  left_join(docvar_df, 
            by = c("document2" = "doc_id")) %>% 
  mutate(same_year = as.factor(ifelse(plan_year.x == plan_year.y, 1, 0)),
         same_pop = as.factor(ifelse(pop_bin.x == pop_bin.y, 1, 0)),
         same_mhi = as.factor(ifelse(mhi_bin.x == mhi_bin.y, 1, 0)),
         same_county = as.factor(ifelse(county.x == county.y, 1, 0)),
         both_used_consultant = as.factor(ifelse(used_consultant.x == 1 & used_consultant.y == 1, 1, 0)),
         length_dif = abs(plan_length.x - plan_length.y)
         ) %>%
  select(-c(plan_year.x, plan_year.y, 
            plan_length.x, plan_length.y, 
            city_name.x, city_name.y,
            pop_bin.x, pop_bin.y, 
            mhi_bin.x, mhi_bin.y,
            county.x, county.y))


mod_1 <- lm(log(cosine) ~ both_used_consultant,
            data = eje_sim_df) 

mod_2 <- lm(log(cosine) ~ both_used_consultant + same_county + same_year,
            data = eje_sim_df) 

mod_3 <- lm(log(cosine) ~ both_used_consultant + same_pop + same_mhi ,
            data = eje_sim_df) 

mod_4 <- lm(log(cosine) ~ both_used_consultant + same_county + same_year + same_pop + same_mhi ,
            data = eje_sim_df) 

```

# Introduction

In 2016, the state of California passed Senate Bill 1000, which required that certain general plans address environmental justice (EJ), in addition to previously required elements including housing, land use, safety, and others. Previous research suggests that these plans vary greatly in their content and that further research should seek to explain "the context in which plans were made \[...\], including the use of consultants" [@brinkley2024, pp. 68]. This article intends to do just that, by questioning what effect the use of consulting firms has on the similarity between environmental justice elements. A greater understanding of how consultants impact the policy development process can have normative implications for the policies that are developed in the EJ context, which prioritizes localized, participatory development over centralized or standardized approaches. Further, consultants are frequently used in the environmental policy process, particularly in the environmental review process, and results may indicate further avenues of research.

Here, I focus on a single hypothesis regarding the use of consultants. Previous research on boilerplate text has indicated that documents sharing consulting firms have increased use of boilerplate text [@scott2022]. Further, the use of consultants is often intended to reduce friction in the review process through normalized and standardized processes [@kingsley2017]. As such, I hypothesize that the use of consulting firms in the development of EJ elements will lead to increased similarity between documents.

# Methods

The General Plan Database Mapping Tool was used to conduct this analysis (plansearch.caes.ucdavis.edu). This database was constructed through manual compilation of relevant general plan documents across California cities, and is primarily used as a website which allows users to search for a term across all plans available in the database [@banginwar2023; @poirier2024]. The database has been updated several times since its initial use in a 2017 article \[CITE\]. Documents were manually downloaded from the website and totaled 361 unique documents at the time of download, covering 288 unique cities.

Documents were transformed from the pdf format to text corpuses using the `pdftools` and `quanteda` packages in R. Whitespace characters such as newline (`\n`) were removed but documents were otherwise unaltered. After an initial review of documents it was necessary to tag the specific type of general plan document for each, as the dataset included general plans, housing elements, environmental justice elements, and safety elements. For each document, the first two pages were searched for text specifying which element was listed, such that if "Environmental Justice Element" was on the first page, the document would be tagged as such. For the documents which could not be automatically tagged for some reason, as well as the subset used in this analysis for additional verification, the author manually provided and verified the plan type tags. One limitation of this approach is that EJ elements contained within General Plans, such as the 2011 National City General Plan, are excluded from analysis here.

In total, 13 environmental justice elements were identified, each representing a different California city. These include Antioch in Contra Costa county, Arvin in Kern county, Gardena, Inglewood, Lynwood, Monrovia, and Maywood in Los Angeles county, Menlo Park in San Mateo county, Oakland in Alameda County, Perris and Riverside in Riverside County, Rialto in San Bernardino County, and San Juan Capistrano in Orange county. While these are not the only documents in the dataset that address environmental justice, they are selected due to their topical focus on *only* environmental justice, as opposed to environmental justice in the context of housing or safety.

## Dependent Variable

The dependent variable in this analysis is the similarity between two documents. Several pre-processing steps were taken prior to this calculation. After tokenization, a subset of tokens were removed, including city and county names, stopwords, letters, and the terms "st", "ave", "rd", and "blvd", followed by the removal of punctuation, symbols, and numbers, and finally word stemming. These choices were made after initial analysis highlighted they are among the most common terms in some documents but are substantively unimportant on their own. However, sensitivity testing indicates that results are somewhat robust regardless of their inclusion or exclusion, with the exception of removing city and county names. This is likely due to another pre-processing choice: the weighting of a document feature matrix (DFM) with term frequency - inverse document frequency (TF-IDF) values.

TF-IDF values weight the features (or terms) in a DFM based on their document-level frequency and corpus-level frequency, such that terms which are uniquely frequent in few documents are more heavily weighted than terms which are frequent across all or many documents. As such, this weighting procedure transforms the frequency of a term into the relative frequency of a term. This procedure was selected for this analysis due to the expectation that there would be significant similarity between documents as they are intended to be similar. There are statutory requirements for EJ elements to cover certain topics, including pollution exposure, food access, and civic engagement, among others [@governorsofficeofplanningandresearch2020]. TF-IDF weighting provides a consistent and understandable method of controlling for this expectation. Finally, any terms which only appear in one document are removed, as the nature of comparison between two documents would be biased by terms which appear in one document but not the other.

Given the resultant DFM, cosine similarity was calculated between each pair of documents, for a total of 78 pairwise comparisons. Cosine similarity measures the cosine between two vectors in a high-dimensional space, where each vector is equal in length to the number of features in a DFM. Higher normalized cosine measurements indicate higher similarity between documents.

## Independent Variables

The primary independent variable of analysis is the use of consultants on a given EJ element. This was developed through a manual content analysis by the author. Use of consultant was defined as an explicit reference within the document typically labeled using the phrase "Document prepared by" or the prominent display of a consulting firm logo. The actual consulting firm was recorded but as no two EJ elements shared the same firm, the independent variable is operationalized as two elements both having used a consultant.

Two sets of controls were used for this analysis. First, the thirteen plans are distributed across eight counties, meaning that several of the plans exist in the same county - there are five in Los Angeles county and two in Riverside county. As such, the county within which a city is bounded is included in some models. Similarly, the plans in this dataset were developed between 2021 and 2024, and the year of plan development is included in some models. Second, two socioeconomic variables were gathered from the 2020 American Community Survey, measuring the population and median household income (MHI) of the cities measured. These were collected from the Census API using the `tidycensus` R package. For means of comparing population and MHI, these variables were binned into two groups about the median, thereby measuring if a community is relatively large or small and poor or wealthy.

# Results and Discussion

Given the nature of the data, this analysis uses ordinary least squares regression (OLS). Initial inspection suggests that non-normal distribution of error terms is remedied by transforming the dependent variable into its natural logarithm. Four models are run: the first with only consultant use, the second with consultant use controlling for plan-level variables, the third with consultant use controlling for socioecnomic variables, and the fourth with all controls. The results of this regression analysis are presented in Table 1.

```{r }
#| echo: false
#| results: asis

stargazer(mod_1, mod_2, mod_3, mod_4, 
          type='latex',
          title='Predictors of Logged Cosine Similarity',
          covariate.labels = c(
            'Consultant Used',
            'Same County',
            'Same Year',
            'Same Population Bin',
            'Same MHI Bin'
          ),
          column.sep.width='0pt',
          font.size='small',
          header=FALSE)
```

In each of the four models, there is evidence that the use of consultants in the development of an EJ element is correlated with increased cosine similarity. This effect remains mostly unaffected by the inclusion of further controls, none of which significantly influence the cosine similarity. However, there is also reason to be skeptical about the models including controls, as the associated F statistic is not significant. Combined with the lack of significance for any of the control variables, the simplest first model is perhaps the most reliable. Taking the coefficient from that model, these results suggest that when two EJ elements both use a consultant in their development, the similarity between them increases by 43.6%.

Given these results, one may wonder what is different about the documents produced with a consultant compared to those which were produced without. One approach to understanding these differences is through the frequency with which terms appear in the two groups. Recall that term counts have been weighted using TF-IDF scores, such that the most frequent terms are better interpreted as the most relatively frequent term (in that document). @fig-frequency shows the most common twenty words in each group, highlighting those which appear in both.

```{r}
#| label: fig-frequency
#| fig-cap: "Weighted Term Frequency in Environmental Justice Elements"
#| echo: false
#| results: asis

freqs <- ej_dfm %>%
  textstat_frequency(groups=used_consultant, force=TRUE) %>%
  group_by(group) %>%
  slice_max(order_by = frequency, n = 30) %>%
  arrange(group, desc(frequency)) %>% 
  mutate(group = ifelse(group == 1, "Used Consultant", "Did Not Use Consultant")) %>% 
  ungroup()

appear_in_both <- count(freqs, feature) %>% 
  filter(n>1) %>% 
  pull(feature)

freqs <- freqs %>% 
  mutate(appear_in_both = as.factor(ifelse(feature %in% appear_in_both, 1, 0)) )


freqs %>%
  ggplot(aes(x = reorder(feature, frequency), y = frequency)) +
  geom_col(aes(fill=appear_in_both)) +
  facet_wrap(~ group, 
             scales = "free_y") +
  coord_flip() +
  labs(x = "Feature", y = "TF-IDF Weighted Frequency") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        legend.position = 'none')
```

While this sample is small, there are a few intuitive points which can be gleaned from this approach. First, there are several geographic locations which contribute to the similarity measures that should be removed as research progresses - evergreen, pomona, magnolia, and belle haven are either neighborhoods or locations which uniquely identify a certain city, and would ideally be removed. Second, there are a small number of words which appear frequently in both consulted and non-consulted plans, including RHNA, or the Regional Housing Needs Allocation, which measures the need for housing in a community, which may indicate that regardless of consultant use, this metric is used to provide for one form of environmental justice. Finally, while @brinkley2024 found that discussion of race was not frequent in EJ plans, this analysis highlights that both the terms "latinx" and "segregation" appear frequently in consulted plans. While certainly not causal, this suggests that consulted projects are perhaps more likely to include race. Further research would need to investigate this across a broader set of plans, potentially also controlling for racial or ethnic sub-populations within a city.

# Conclusion

This research has made initial progress towards an understanding of how novel topics of planning emerge. I show that two planning elements which are both written by consultants are significantly more likely to be similar than other pairwise comparisons. In this analysis, I make best efforts to limit the corpuses being compared such that they highlight substantively unique features, rather than local details or generic, frequently used terms. However, there are two directions of further effort towards a greater understanding of the role of consultants on planning documents.

First, this research could be performed in greater depth. Here I highlight a correlation between consultant use and similarity, and suggest some of the terms that may be unique to consultants, but there is no proper understanding of what consultants are actually doing differently. Developing hypotheses based on the literature about how consultants act, what tasks they are assigned, and how the complete these would provide one step in this direction. This hypotheses could be tested by moving from term-based models of documents to topic-based models, where semantic meaning is measured rather than the frequency or similarity of various terms. Such an approach would likely require a more atomic view of each document to compare if, when, and where various topics are discussed.

Second, this research could be conducted with greater breadth. Here, the sample reflects a best initial effort at the universe of environmental justice elements, but there EJ elements which are buried within general plans not analyzed here, as well as potential documents not included in the dataset used. Further, cities have the option of developing a standalone EJ element or integrating the necessary materiel within other elements. Afforementioned topic-based models may be similarly useful to parse out where and how city planning documents more broadly discuss EJ and allow for comparison between documents where there is a greater expectation of dissimilarity. Further, a broader dataset would likely include plans which use the same consultant, allowing for an additional level of control in the models.

# Works Cited
